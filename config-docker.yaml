server:
  host: "0.0.0.0"
  port: 7999
  output_path: "/app/storage/output"
  api_key: cbebbe70-0ba4-494f-8c85-41da575228d9

ollama:
  host: "host.docker.internal"
  port: 11434
  timeout: 600  # секунды
  default_model: "hf.co/RefalMachine/RuadaptQwen2.5-32B-Pro-Beta-GGUF:Q8_0"

openapi:
  title: "AI Gateway"
  version: "1.0.0"
  summary: "Сервер управления LLM моделями Ollama и Hugging Face"
  description: |
    <table>
      <tr>
        <th align= "left">Ключевая информация</th>
        <th align= "left">Технические детали</th>
      </tr>
      <tr>
      <td valign="top">
        <ul>
          <li>Используется исключительно для личных целей владельца</li>  
          <li>Не предназначен для публичного использования</li>  
          <li>Доступ только для аутентифицированных пользователей</li>
        </ul>
      </td>
      <td valign="top">
        <ul>
          <li>Поддержка запуска моделей, управляемых сервером <a href="https://ollama.com/">Ollama</a></li>
          <li>Поддержка запуска локальных моделей <a href="https://huggingface.co/">Hugging Face</a></li>
          <li>Совместимость с OpenAI API</li>
        </ul>  
      </td>
      </tr>
    </table>
  contact:
    name: "Nikolay Sedov"
    url: "https://nicksedov.github.io/"
  license_info:
    name: "ТОЛЬКО ДЛЯ ЛИЧНОГО ИСПОЛЬЗОВАНИЯ"
  security_schemes:
    Bearer:
      type: "http"
      scheme: "bearer"
      bearerFormat: "UUID"
      description: "Требуемый формат: UUID"
  security:
    - Bearer: []

chat:
  image_generation:
    default_model: "black-forest-labs/FLUX.1-dev"
    default_size: "512x512"
    default_steps: 25
    default_guidance_scale: 4.5
    default_language: "auto"
  image_prompt:

    temperature: 0.7
    top_p: 0.9
    max_tokens: 300
    system_message: "Сейчас ты помогаешь создавать промпты для генерации изображений."

logging:
  file_path: "/var/log/ai-server.log"
  level: "INFO"
  format: "%(asctime)s [%(name)-16s] %(levelname)s %(message)s"
  datefmt: "%Y-%m-%d %H:%M:%S"