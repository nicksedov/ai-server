server:
  host: "0.0.0.0"
  port: 7999
  output_path: "/app/storage/output"
  api_key: cbebbe70-0ba4-494f-8c85-41da575228d9

ollama:
  host: "host.docker.internal"
  port: 11434
  timeout: 300  # seconds
  default_model: "qwq:32b-q8_0"

openapi:
  title: "LLM Server API"
  version: "1.0.0"
  summary: "Private LLM model management server"
  description: |
    <table>
      <tr>
        <th align= "left">Key Information</th>
        <th align= "left">Technical Details</th>
      </tr>
      <tr>
      <td valign="top">
        <ul>
          <li>Used exclusively for owner's personal purposes</li>  
          <li>Testing and deployment of LLMs</li>  
          <li>Not intended for public use</li>  
          <li>Access strictly limited</li>
        </ul>
      </td>
      <td valign="top">
        <ul>
          <li>Integrated with Ollama</li>
          <li>Huggingface models support</li>
          <li>OpenAI API compatible</li>
          <li>Private deployment only</li>
        </ul>  
      </td>
      </tr>
    </table>
  contact:
    name: "Nikolay Sedov"
    url: "https://nicksedov.github.io/"
  license_info:
    name: "PRIVATE USE ONLY"
  security_schemes:
    Bearer:
      type: "http"
      scheme: "bearer"
      bearerFormat: "UUID"
      description: "Required format: Bearer <your-secret-key>"
  security:
    - Bearer: []
