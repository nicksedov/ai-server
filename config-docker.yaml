server:
  host: "0.0.0.0"
  port: 7999
  output_path: "/app/storage/output"
  api_key: cbebbe70-0ba4-494f-8c85-41da575228d9

ollama:
  host: "host.docker.internal"
  port: 11434
  timeout: 300  # секунды
  default_model: "hf.co/RefalMachine/RuadaptQwen2.5-32B-Pro-Beta-GGUF:Q8_0"

openapi:
  title: "AI Gateway"
  version: "1.0.0"
  summary: "Сервер управления LLM моделями Ollama и Hugging Face"
  description: |
    <table>
      <tr>
        <th align= "left">Ключевая информация</th>
        <th align= "left">Технические детали</th>
      </tr>
      <tr>
      <td valign="top">
        <ul>
          <li>Используется исключительно для личных целей владельца</li>  
          <li>Не предназначен для публичного использования</li>  
          <li>Доступ только для аутентифицированных пользователей</li>
        </ul>
      </td>
      <td valign="top">
        <ul>
          <li>Поддержка запуска моделей, управляемых сервером <a href="https://ollama.com/">Ollama</a></li>
          <li>Поддержка запуска локальных моделей <a href="https://huggingface.co/">Hugging Face</a></li>
          <li>Совместимость с OpenAI API</li>
        </ul>  
      </td>
      </tr>
    </table>
  contact:
    name: "Nikolay Sedov"
    url: "https://nicksedov.github.io/"
  license_info:
    name: "ТОЛЬКО ДЛЯ ЛИЧНОГО ИСПОЛЬЗОВАНИЯ"
  security_schemes:
    Bearer:
      type: "http"
      scheme: "bearer"
      bearerFormat: "UUID"
      description: "Требуемый формат: UUID"
  security:
    - Bearer: []

logging:
  file_path: "/var/log/ai-server.log"
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  max_bytes: 10485760
  backup_count: 5
  enable_console: true